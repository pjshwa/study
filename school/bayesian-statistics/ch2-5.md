### No definitive definition of *probability*
- 확률은 그냥 내가 “어느 정도일 거야” 라고 생각하는 수치일 뿐이다.
- In constrast to the Frequentists’ view of probability: 확률은 비율이고, 이 비율은 실험을 계속 했을 때 사건이 일어나는 빈도가 수렴하는 값이다.
- 수학적인 틀은 모두 동일하다. (theorems, definition of some distributions ..)
- 하지만 parameter 에 대한 생각이 다르므로, 분석 결과는 다르다.

### 복습
- Marginal dist, Likelihood function.


- 1장은 각자 읽어라.

## Chapter 2
### Prior and Posterior
- 사전적인 의미는, ‘전’과 ‘후’이지만 … 그렇지 않은 경우도 있다.
- 따라서 각각 Data 를 배제한/포함한 분포 라고 보는 것이 맞다.
- 예) 데이터를 모으는 중에/모은 뒤에 전문가의 고견을 듣게 됨.

### Goals of Inference from Data
- Parameter 값 예측
- 자료를 predict (past data, missing data ..)
- Model 비교 → pdf 에 대한 시각 차이: Frequentist 는 f(x; theta) (dist given theta), Bayesian 은 f(x|theta) (dist of x conditional to theta.. two random variables!)

### {X, Y, theta}
- f(x, y, theta) =/= f(x)f(y)f(theta) (교수님 첨언: 이러면 Bayesian 을 할 필요가 없다 … 자료 때문에 prior distn 이 변경되지 않았으므로.)
- BUT f(x, y | theta) = f(x | theta) f(y | theta) (교수님 첨언: 이렇다고 해서 f(x, y) = f(x) f(y) 인 것은 아니다. 반대의 경우에는? Bayesian 을 할 필요가 있나?)

### Model Comparison
- 모델은 가짜다! 데이터를 잘 설명할 수 있는, 최대한 비슷한 모델을 고른다.
- P(model1 | {x1 … xn}) = 0.4, P(model2 | {x1 … xn}) = 0.6
- Model2 가 더 가능성이 높으니까 이걸 채택함.

## Chapter 5 (Bayes’ Rule)
### P(D) : “My” Evidence.
- P(D) = *S* P(D/theta) P(theta) d theta. cf) E[X] = *S* x f(x) dx.
- Weighted average (P(theta)) of all data dependent on theta (P(D|theta))

### {D, theta}
- P(D, theta) (joint)
- P(D), P(theta) (marginal)
- P(D|theta), P(theta|D) (prior, posterior conditional)

### Data order invariance
- P(theta|D1, D2) = P(theta|D2, D1) if data are iid.
- **HW** 
